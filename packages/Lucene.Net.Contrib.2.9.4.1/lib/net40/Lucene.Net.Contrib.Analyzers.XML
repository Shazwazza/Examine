<?xml version="1.0"?>
<doc>
    <assembly>
        <name>Lucene.Net.Contrib.Analyzers</name>
    </assembly>
    <members>
        <member name="T:Lucene.Net.Analysis.AR.ArabicAnalyzer">
            <see cref="T:Lucene.Net.Analysis.Analyzer"/> for Arabic. 
            <p/>
            This analyzer implements light-stemming as specified by:
            <i>
            Light Stemming for Arabic Information Retrieval
            </i>    
            http://www.mtholyoke.edu/~lballest/Pubs/arab_stem05.pdf
            <p/>
            The analysis package contains three primary components:
            <ul>
             <li><see cref="T:Lucene.Net.Analysis.AR.ArabicNormalizationFilter"/>: Arabic orthographic normalization.</li>
             <li><see cref="T:Lucene.Net.Analysis.AR.ArabicStemFilter"/>: Arabic light stemming</li>
             <li>Arabic stop words file: a set of default Arabic stop words.</li>
            </ul>
            
        </member>
        <member name="F:Lucene.Net.Analysis.AR.ArabicAnalyzer.DEFAULT_STOPWORD_FILE">
            File containing default Arabic stopwords.
            
            Default stopword list is from http://members.unine.ch/jacques.savoy/clef/index.html
            The stopword list is BSD-Licensed.
        </member>
        <member name="F:Lucene.Net.Analysis.AR.ArabicAnalyzer.stoptable">
            Contains the stopwords used with the StopFilter.
        </member>
        <member name="F:Lucene.Net.Analysis.AR.ArabicAnalyzer.STOPWORDS_COMMENT">
            The comment character in the stopwords file.  All lines prefixed with this will be ignored  
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor">
             Builds an analyzer with the default stop words: <see cref="F:Lucene.Net.Analysis.AR.ArabicAnalyzer.DEFAULT_STOPWORD_FILE"/>.
            
             @deprecated Use <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version)"/> instead
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version)">
            Builds an analyzer with the default stop words: <see cref="F:Lucene.Net.Analysis.AR.ArabicAnalyzer.DEFAULT_STOPWORD_FILE"/>.
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(System.String[])">
             Builds an analyzer with the given stop words.
            
             @deprecated Use <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version,System.String[])"/> instead
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version,System.String[])">
            Builds an analyzer with the given stop words.
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(System.Collections.Hashtable)">
             Builds an analyzer with the given stop words.
            
             @deprecated Use <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version,System.Collections.Hashtable)"/> instead
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.#ctor(Lucene.Net.Util.Version,System.Collections.Hashtable)">
            Builds an analyzer with the given stop words.
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.TokenStream(System.String,System.IO.TextReader)">
             Creates a <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.TokenStream(System.String,System.IO.TextReader)"/> which tokenizes all the text in the provided <see cref="T:System.IO.TextReader"/>.
            
             <returns>A <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.TokenStream(System.String,System.IO.TextReader)"/> built from an <see cref="T:Lucene.Net.Analysis.AR.ArabicLetterTokenizer"/> filtered with
             			<see cref="T:Lucene.Net.Analysis.LowerCaseFilter"/>, <see cref="T:Lucene.Net.Analysis.StopFilter"/>, <see cref="T:Lucene.Net.Analysis.AR.ArabicNormalizationFilter"/>
                        and <see cref="T:Lucene.Net.Analysis.AR.ArabicStemFilter"/>.</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.ReusableTokenStream(System.String,System.IO.TextReader)">
             Returns a (possibly reused) <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.TokenStream(System.String,System.IO.TextReader)"/> which tokenizes all the text 
             in the provided <see cref="T:System.IO.TextReader"/>.
            
             <returns>A <see cref="M:Lucene.Net.Analysis.AR.ArabicAnalyzer.TokenStream(System.String,System.IO.TextReader)"/> built from an <see cref="T:Lucene.Net.Analysis.AR.ArabicLetterTokenizer"/> filtered with
                        <see cref="T:Lucene.Net.Analysis.LowerCaseFilter"/>, <see cref="T:Lucene.Net.Analysis.StopFilter"/>, <see cref="T:Lucene.Net.Analysis.AR.ArabicNormalizationFilter"/>
                        and <see cref="T:Lucene.Net.Analysis.AR.ArabicStemFilter"/>.</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.AR.ArabicLetterTokenizer">
             Tokenizer that breaks text into runs of letters and diacritics.
             <p>
             The problem with the standard Letter tokenizer is that it fails on diacritics.
             Handling similar to this is necessary for Indic Scripts, Hebrew, Thaana, etc.
             </p>
            
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicLetterTokenizer.IsTokenChar(System.Char)">
            Allows for Letter category or NonspacingMark category
            <see cref="M:Lucene.Net.Analysis.LetterTokenizer.IsTokenChar(System.Char)"/>
        </member>
        <member name="T:Lucene.Net.Analysis.AR.ArabicNormalizationFilter">
            A <see cref="T:Lucene.Net.Analysis.TokenFilter"/> that applies <see cref="T:Lucene.Net.Analysis.AR.ArabicNormalizer"/> to normalize the orthography.
            
        </member>
        <member name="T:Lucene.Net.Analysis.AR.ArabicNormalizer">
              Normalizer for Arabic.
              <p/>
              Normalization is done in-place for efficiency, operating on a termbuffer.
              <p/>
              Normalization is defined as:
              <ul>
              <li> Normalization of hamza with alef seat to a bare alef.</li>
              <li> Normalization of teh marbuta to heh</li>
              <li> Normalization of dotless yeh (alef maksura) to yeh.</li>
              <li> Removal of Arabic diacritics (the harakat)</li>
              <li> Removal of tatweel (stretching character).</li>
             </ul>
            
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicNormalizer.Normalize(System.Char[],System.Int32)">
            Normalize an input buffer of Arabic text
            
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <returns>length of input buffer after normalization</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicNormalizer.Delete(System.Char[],System.Int32,System.Int32)">
            Delete a character in-place
            
            <param name="s">Input Buffer</param>
            <param name="pos">Position of character to delete</param>
            <param name="len">length of input buffer</param>
            <returns>length of input buffer after deletion</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.AR.ArabicStemFilter">
            A <see cref="T:Lucene.Net.Analysis.TokenFilter"/> that applies <see cref="T:Lucene.Net.Analysis.AR.ArabicStemmer"/> to stem Arabic words..
            
        </member>
        <member name="T:Lucene.Net.Analysis.AR.ArabicStemmer">
              Stemmer for Arabic.
              <p/>
              Stemming  is done in-place for efficiency, operating on a termbuffer.
              <p/>
              Stemming is defined as:
              <ul>
              <li> Removal of attached definite article, conjunction, and prepositions.</li>
              <li> Stemming of common suffixes.</li>
             </ul>
            
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.Stem(System.Char[],System.Int32)">
            Stem an input buffer of Arabic text.
            
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <returns>length of input buffer after normalization</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.StemPrefix(System.Char[],System.Int32)">
            Stem a prefix off an Arabic word.
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <returns>new length of input buffer after stemming.</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.StemSuffix(System.Char[],System.Int32)">
            Stem suffix(es) off an Arabic word.
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <returns>new length of input buffer after stemming</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.StartsWith(System.Char[],System.Int32,System.Char[])">
            Returns true if the prefix matches and can be stemmed
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <param name="prefix">prefix to check</param>
            <returns>true if the prefix matches and can be stemmed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.EndsWith(System.Char[],System.Int32,System.Char[])">
            Returns true if the suffix matches and can be stemmed
            <param name="s">input buffer</param>
            <param name="len">length of input buffer</param>
            <param name="suffix">suffix to check</param>
            <returns>true if the suffix matches and can be stemmed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.DeleteN(System.Char[],System.Int32,System.Int32,System.Int32)">
            Delete n characters in-place
            
            <param name="s">Input Buffer</param>
            <param name="pos">Position of character to delete</param>
            <param name="len">Length of input buffer</param>
            <param name="nChars">number of characters to delete</param>
            <returns>length of input buffer after deletion</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.AR.ArabicStemmer.Delete(System.Char[],System.Int32,System.Int32)">
            Delete a character in-place
            
            <param name="s">Input Buffer</param>
            <param name="pos">Position of character to delete</param>
            <param name="len">length of input buffer</param>
            <returns>length of input buffer after deletion</returns>
        </member>
        <member name="F:Lucene.Net.Analysis.BR.BrazilianAnalyzer.BRAZILIAN_STOP_WORDS">
            List of typical Brazilian stopwords.
        </member>
        <member name="F:Lucene.Net.Analysis.BR.BrazilianAnalyzer.stoptable">
            Contains the stopwords used with the StopFilter.
        </member>
        <member name="F:Lucene.Net.Analysis.BR.BrazilianAnalyzer.excltable">
            Contains words that should be indexed but not stemmed.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.#ctor">
            Builds an analyzer with the default stop words (<see cref="F:Lucene.Net.Analysis.BR.BrazilianAnalyzer.BRAZILIAN_STOP_WORDS"/>).
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.#ctor(System.String[])">
            Builds an analyzer with the given stop words.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.#ctor(System.Collections.Hashtable)">
            Builds an analyzer with the given stop words.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.#ctor(System.IO.FileInfo)">
            Builds an analyzer with the given stop words.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.SetStemExclusionTable(System.String[])">
            Builds an exclusionlist from an array of Strings.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.SetStemExclusionTable(System.Collections.Hashtable)">
            Builds an exclusionlist from a Hashtable.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.SetStemExclusionTable(System.IO.FileInfo)">
            Builds an exclusionlist from the words contained in the given file.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianAnalyzer.TokenStream(System.String,System.IO.TextReader)">
             Creates a TokenStream which tokenizes all the text in the provided Reader.
            
             <returns>A TokenStream build from a StandardTokenizer filtered with
             			StandardFilter, StopFilter, GermanStemFilter and LowerCaseFilter.</returns>
        </member>
        <member name="F:Lucene.Net.Analysis.BR.BrazilianStemFilter.stemmer">
            The actual token in the input stream.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemFilter.Next(Lucene.Net.Analysis.Token)">
            <returns>Returns the next token in the stream, or null at EOS.</returns>
        </member>
        <member name="F:Lucene.Net.Analysis.BR.BrazilianStemmer.TERM">
            Changed term
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.Stem(System.String)">
             Stemms the given term to an unique <tt>discriminator</tt>.
            
             <param name="term"> The term that should be stemmed.</param>
             <returns>     Discriminator for <tt>term</tt></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.isStemmable(System.String)">
             Checks a term if it can be processed correctly.
            
             <returns> true if, and only if, the given term consists in letters.</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.isIndexable(System.String)">
             Checks a term if it can be processed indexed.
            
             <returns> true if it can be indexed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.isVowel(System.Char)">
                     * See if string is 'a','e','i','o','u'
                   *
                   * <returns>true if is vowel</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.getR1(System.String)">
                     * Gets R1
                   *
                   * R1 - is the region after the first non-vowel follwing a vowel,
                   *      or is the null region at the end of the word if there is
                   *      no such non-vowel.
                   *
                   * <returns>null or a string representing R1</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.getRV(System.String)">
                     * Gets RV
                   *
                   * RV - IF the second letter is a consoant, RV is the region after
                   *      the next following vowel,
                   *
                   *      OR if the first two letters are vowels, RV is the region
                   *      after the next consoant,
                   *
                   *      AND otherwise (consoant-vowel case) RV is the region after
                   *      the third letter.
                   *
                   *      BUT RV is the end of the word if this positions cannot be
                   *      found.
                   *
                   * <returns>null or a string representing RV</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.changeTerm(System.String)">
             1) Turn to lowercase
             2) Remove accents
             3) ã -> a ; õ -> o
             4) ç -> c
            
             <returns>null or a string transformed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.suffix(System.String,System.String)">
             Check if a string ends with a suffix
            
             <returns>true if the string ends with the specified suffix</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.replaceSuffix(System.String,System.String,System.String)">
             Replace a string suffix by another
            
             <returns>the replaced string</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.removeSuffix(System.String,System.String)">
             Remove a string suffix
            
             <returns>the string without the suffix</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.suffixPreceded(System.String,System.String,System.String)">
             See if a suffix is preceded by a string
            
             <returns>true if the suffix is preceded</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.createCT(System.String)">
            Creates CT (changed term) , substituting * 'ã' and 'õ' for 'a~' and 'o~'.
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.step1">
                     * Standart suffix removal.
                   * Search for the longest among the following suffixes, and perform
                   * the following actions:
                   *
                   * <returns>false if no ending was removed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.step2">
                     * Verb suffixes.
                   *
                   * Search for the longest among the following suffixes in RV,
                   * and if found, delete.
                   *
                   * <returns>false if no ending was removed</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.step3">
                     * Delete suffix 'i' if in RV and preceded by 'c'
                   *
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.step4">
                     * Residual suffix
                   *
                   * If the word ends with one of the suffixes (os a i o á í ó)
                   * in RV, delete it
                   *
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.step5">
                     * If the word ends with one of ( e é ê) in RV,delete it,
                   * and if preceded by 'gu' (or 'ci') with the 'u' (or 'i') in RV,
                   * delete the 'u' (or 'i')
                   *
                   * Or if the word ends ç remove the cedilha
                   *
        </member>
        <member name="M:Lucene.Net.Analysis.BR.BrazilianStemmer.Log">
             For log and debug purpose
            
             <returns> TERM, CT, RV, R1 and R2</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.CJK.CJKAnalyzer">
            <summary>
            Filters CJKTokenizer with StopFilter.
            
            <author>Che, Dong</author>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKAnalyzer.stopWords">
            <summary>
            An array containing some common English words that are not usually
            useful for searching. and some double-byte interpunctions.....
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKAnalyzer.stopTable">
            <summary>
            stop word list
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CJK.CJKAnalyzer.#ctor">
            <summary>
            Builds an analyzer which removes words in STOP_WORDS.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CJK.CJKAnalyzer.#ctor(System.String[])">
            <summary>
            Builds an analyzer which removes words in the provided array.
            </summary>
            <param name="stopWords">stop word array</param>
        </member>
        <member name="M:Lucene.Net.Analysis.CJK.CJKAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            get token stream from input
            </summary>
            <param name="fieldName">lucene field name</param>
            <param name="reader">input reader</param>
            <returns>Token Stream</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.CJK.CJKTokenizer">
            <summary>
            <p>
            CJKTokenizer was modified from StopTokenizer which does a decent job for
            most European languages. and it perferm other token method for double-byte
            Characters: the token will return at each two charactors with overlap match.<br/>
            Example: "java C1C2C3C4" will be segment to: "java" "C1C2" "C2C3" "C3C4" it
            also need filter filter zero length token ""<br/>
            for Digit: digit, '+', '#' will token as letter<br/>
            for more info on Asia language(Chinese Japanese Korean) text segmentation:
            please search  <a
            href="http://www.google.com/search?q=word+chinese+segment">google</a>
            </p>
            
            @author Che, Dong
            @version $Id: CJKTokenizer.java,v 1.3 2003/01/22 20:54:47 otis Exp $
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.MAX_WORD_LEN">
            <summary>
            Max word length
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.IO_BUFFER_SIZE">
            <summary>
            buffer size
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.offset">
            <summary>
            word offset, used to imply which character(in ) is parsed
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.bufferIndex">
            <summary>
            the index used only for ioBuffer
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.dataLen">
            <summary>
            data length
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.buffer">
            <summary>
            character buffer, store the characters which are used to compose <br/>
            the returned Token
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.ioBuffer">
            <summary>
            I/O buffer, used to store the content of the input(one of the <br/>
            members of Tokenizer)
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.tokenType">
            <summary>
            word type: single=>ASCII  double=>non-ASCII word=>default 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.CJK.CJKTokenizer.preIsTokened">
            <summary>
            tag: previous character is a cached double-byte character  "C1C2C3C4"
            ----(set the C1 isTokened) C1C2 "C2C3C4" ----(set the C2 isTokened)
            C1C2 C2C3 "C3C4" ----(set the C3 isTokened) "C1C2 C2C3 C3C4"
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.CJK.CJKTokenizer.#ctor(System.IO.TextReader)">
            <summary>
            Construct a token stream processing the given input.
            </summary>
            <param name="_in">I/O reader</param>
        </member>
        <member name="M:Lucene.Net.Analysis.CJK.CJKTokenizer.Next">
            <summary>
             Returns the next token in the stream, or null at EOS.
            </summary>
            <returns>Token</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Cn.ChineseAnalyzer">
            <summary>
            Title: ChineseAnalyzer
            Description:
              Subclass of org.apache.lucene.analysis.Analyzer
              build from a ChineseTokenizer, filtered with ChineseFilter.
            Copyright:   Copyright (c) 2001
            Company:
            <author>Yiyi Sun</author>
            <version>$Id: ChineseAnalyzer.java, v 1.2 2003/01/22 20:54:47 ehatcher Exp $</version>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cn.ChineseAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided Reader.
            </summary>
            <returns>A TokenStream build from a ChineseTokenizer filtered with ChineseFilter.</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Cn.ChineseFilter">
            <summary>
            Title: ChineseFilter
            Description: Filter with a stop word table
                         Rule: No digital is allowed.
                               English word/token should larger than 1 character.
                               One Chinese character as one Chinese word.
            TO DO:
              1. Add Chinese stop words, such as \ue400
              2. Dictionary based Chinese word extraction
              3. Intelligent Chinese word extraction
            
            Copyright:    Copyright (c) 2001
            Company:
            <author>Yiyi Sun</author>
            <version>$Id: ChineseFilter.java, v 1.4 2003/01/23 12:49:33 ehatcher Exp $</version>
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Cn.ChineseTokenizer">
            <summary>
            Title: ChineseTokenizer
            Description: Extract tokens from the Stream using Character.getType()
                         Rule: A Chinese character as a single token
            Copyright:   Copyright (c) 2001
            Company:
            
            The difference between thr ChineseTokenizer and the
            CJKTokenizer (id=23545) is that they have different
            token parsing logic.
            
            Let me use an example. If having a Chinese text
            "C1C2C3C4" to be indexed, the tokens returned from the
            ChineseTokenizer are C1, C2, C3, C4. And the tokens
            returned from the CJKTokenizer are C1C2, C2C3, C3C4.
            
            Therefore the index the CJKTokenizer created is much
            larger.
            
            The problem is that when searching for C1, C1C2, C1C3,
            C4C2, C1C2C3 ... the ChineseTokenizer works, but the
            CJKTokenizer will not work.
            <author>Yiyi Sun</author>
            <version>$Id: ChineseTokenizer.java, v 1.4 2003/03/02 13:56:03 otis Exp $</version>
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Cz.CzechAnalyzer">
            <summary>
            Analyzer for Czech language. Supports an external list of stopwords (words that
            will not be indexed at all).
            A default set of stopwords is used unless an alternative list is specified, the
            exclusion list is empty by default.
            
            <author>Lukas Zapletal [lzap@root.cz]</author>
            <version>$Id: CzechAnalyzer.java,v 1.2 2003/01/22 20:54:47 ehatcher Exp $</version>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Cz.CzechAnalyzer.STOP_WORDS">
            <summary>
            List of typical stopwords.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Cz.CzechAnalyzer.stoptable">
            <summary>
            Contains the stopwords used with the StopFilter.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.#ctor">
            <summary>
            Builds an analyzer.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.#ctor(System.String[])">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.LoadStopWords(System.IO.Stream,System.String)">
            <summary>
            Loads stopwords hash from resource stream (file, database...).
            </summary>
            <param name="wordfile">File containing the wordlist</param>
            <param name="encoding">Encoding used (win-1250, iso-8859-2, ...}, null for default system encoding</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Cz.CzechAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided Reader.
            </summary>
            <returns>
            A TokenStream build from a StandardTokenizer filtered with
            StandardFilter, StopFilter, GermanStemFilter and LowerCaseFilter
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.De.GermanAnalyzer">
            <summary>
            Analyzer for German language. Supports an external list of stopwords (words that
            will not be indexed at all) and an external list of exclusions (word that will
            not be stemmed, but indexed).
            A default set of stopwords is used unless an alternative list is specified, the
            exclusion list is empty by default.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanAnalyzer.GERMAN_STOP_WORDS">
            <summary>
            List of typical german stopwords.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanAnalyzer.stoptable">
            <summary>
            Contains the stopwords used with the StopFilter. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanAnalyzer.excltable">
            <summary>
            Contains words that should be indexed but not stemmed. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.#ctor">
            <summary>
            Builds an analyzer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.#ctor(System.String[])">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.SetStemExclusionTable(System.String[])">
            <summary>
            Builds an exclusionlist from an array of Strings. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.SetStemExclusionTable(System.Collections.Hashtable)">
            <summary>
            Builds an exclusionlist from a Hashtable. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.SetStemExclusionTable(System.IO.FileInfo)">
            <summary>
            Builds an exclusionlist from the words contained in the given file. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided TextReader. 
            </summary>
            <param name="fieldName"></param>
            <param name="reader"></param>
            <returns>A TokenStream build from a StandardTokenizer filtered with StandardFilter, StopFilter, GermanStemFilter</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.De.GermanStemFilter">
            <summary>
            A filter that stems German words. It supports a table of words that should
            not be stemmed at all. The stemmer used can be changed at runtime after the
            filter object is created (as long as it is a GermanStemmer).
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanStemFilter.token">
            <summary>
            The actual token in the input stream.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable)">
            <summary>
            Builds a GermanStemFilter that uses an exclusiontable. 
            </summary>
            <param name="_in"></param>
            <param name="exclusiontable"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemFilter.Next">
            <summary>
            </summary>
            <returns>Returns the next token in the stream, or null at EOS</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemFilter.SetStemmer(Lucene.Net.Analysis.De.GermanStemmer)">
            <summary>
            Set a alternative/custom GermanStemmer for this filter. 
            </summary>
            <param name="stemmer"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemFilter.SetExclusionTable(System.Collections.Hashtable)">
            <summary>
            Set an alternative exclusion list for this filter. 
            </summary>
            <param name="exclusiontable"></param>
        </member>
        <member name="T:Lucene.Net.Analysis.De.GermanStemmer">
            <summary>
            A stemmer for German words. The algorithm is based on the report
            "A Fast and Simple Stemming Algorithm for German Words" by JГ¶rg
            Caumanns (joerg.caumanns@isst.fhg.de).
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanStemmer.sb">
            <summary>
            Buffer for the terms while stemming them. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.De.GermanStemmer.substCount">
            <summary>
            Amount of characters that are removed with <tt>Substitute()</tt> while stemming.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.Stem(System.String)">
            <summary>
            Stemms the given term to an unique <tt>discriminator</tt>.
            </summary>
            <param name="term">The term that should be stemmed.</param>
            <returns>Discriminator for <tt>term</tt></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.IsStemmable(System.String)">
            <summary>
            Checks if a term could be stemmed.
            </summary>
            <param name="term"></param>
            <returns>true if, and only if, the given term consists in letters.</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.Strip(System.Text.StringBuilder)">
            <summary>
            Suffix stripping (stemming) on the current term. The stripping is reduced
            to the seven "base" suffixes "e", "s", "n", "t", "em", "er" and * "nd",
            from which all regular suffixes are build of. The simplification causes
            some overstemming, and way more irregular stems, but still provides unique.
            discriminators in the most of those cases.
            The algorithm is context free, except of the length restrictions.
            </summary>
            <param name="buffer"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.Optimize(System.Text.StringBuilder)">
            <summary>
            Does some optimizations on the term. This optimisations are contextual.
            </summary>
            <param name="buffer"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.RemoveParticleDenotion(System.Text.StringBuilder)">
            <summary>
            Removes a particle denotion ("ge") from a term.
            </summary>
            <param name="buffer"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.Substitute(System.Text.StringBuilder)">
             <summary>
             Do some substitutions for the term to reduce overstemming:
            
             - Substitute Umlauts with their corresponding vowel: äöü -> aou,
               "&#223;" is substituted by "ss"
             - Substitute a second char of a pair of equal characters with
             an asterisk: ?? -&gt; ?*
             - Substitute some common character combinations with a token:
               sch/ch/ei/ie/ig/st -&gt; $/В&#167;/%/&amp;/#/!
             </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.GermanStemmer.Resubstitute(System.Text.StringBuilder)">
            <summary>
            Undoes the changes made by Substitute(). That are character pairs and
            character combinations. Umlauts will remain as their corresponding vowel,
            as "?" remains as "ss".
            </summary>
            <param name="buffer"></param>
        </member>
        <member name="T:Lucene.Net.Analysis.De.WordlistLoader">
            <summary>
            Loads a text file and adds every line as an entry to a Hashtable. Every line
            should contain only one word. If the file is not found or on any error, an
            empty table is returned.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.De.WordlistLoader.GetWordtable(System.String,System.String)">
            <summary>
            </summary>
            <param name="path">Path to the wordlist</param>
            <param name="wordfile">Name of the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.WordlistLoader.GetWordtable(System.String)">
            <summary>
            </summary>
            <param name="wordfile">Complete path to the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.WordlistLoader.GetWordtable(System.IO.FileInfo)">
            <summary>
            
            </summary>
            <param name="wordfile">File containing the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.De.WordlistLoader.MakeWordTable(System.String[],System.Int32)">
            <summary>
            Builds the wordlist table.
            </summary>
            <param name="words">Word that where read</param>
            <param name="length">Amount of words that where read into <tt>words</tt></param>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Fr.FrenchAnalyzer">
            <summary>
            Analyzer for french language. Supports an external list of stopwords (words that
            will not be indexed at all) and an external list of exclusions (word that will
            not be stemmed, but indexed).
            A default set of stopwords is used unless an other list is specified, the
            exclusionlist is empty by default.
            
            <author>Patrick Talbot (based on Gerhard Schwarz work for German)</author>
            <version>$Id: FrenchAnalyzer.java,v 1.9 2004/10/17 11:41:40 dnaber Exp $</version>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchAnalyzer.FRENCH_STOP_WORDS">
            <summary>
            Extended list of typical french stopwords.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchAnalyzer.stoptable">
            <summary>
            Contains the stopwords used with the StopFilter.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchAnalyzer.excltable">
            <summary>
            Contains words that should be indexed but not stemmed.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.#ctor">
            <summary>
            Builds an analyzer.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.#ctor(System.String[])">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.SetStemExclusionTable(System.String[])">
            <summary>
            Builds an exclusionlist from an array of Strings.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.SetStemExclusionTable(System.Collections.Hashtable)">
            <summary>
            Builds an exclusionlist from a Hashtable.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.SetStemExclusionTable(System.IO.FileInfo)">
            <summary>
            Builds an exclusionlist from the words contained in the given file.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided Reader.
            </summary>
            <returns>
            A TokenStream build from a StandardTokenizer filtered with
            	StandardFilter, StopFilter, FrenchStemFilter and LowerCaseFilter
            </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Fr.FrenchStemFilter">
            <summary>
            A filter that stemms french words. It supports a table of words that should
            not be stemmed at all. The used stemmer can be changed at runtime after the
            filter object is created (as long as it is a FrenchStemmer).
            
            <author>Patrick Talbot (based on Gerhard Schwarz work for German)</author>
            <version>$Id: FrenchAnalyzer.java,v 1.2 2004/01/23 20:54:47 ehatcher Exp $</version>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemFilter.token">
            <summary>
            The actual token in the input stream.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable)">
            <summary>
            Builds a FrenchStemFilter that uses an exclusiontable.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemFilter.Next">
            <summary>
            Returns the next token in the stream, or null at EOS
            </summary>
            <returns>
            Returns the next token in the stream, or null at EOS
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemFilter.SetStemmer(Lucene.Net.Analysis.Fr.FrenchStemmer)">
            <summary>
            Set a alternative/custom FrenchStemmer for this filter.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemFilter.SetExclusionTable(System.Collections.Hashtable)">
            <summary>
            Set an alternative exclusion list for this filter.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Fr.FrenchStemmer">
            <summary>
            A stemmer for French words. The algorithm is based on the work of
            Dr Martin Porter on his snowball project<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html<br/>
            (French stemming algorithm) for details
            
            <author>Patrick Talbot (based on Gerhard Schwarz work for German)</author>
            <version>$Id: FrenchStemmer.java,v 1.2 2004/01/22 20:54:47 ehatcher Exp $</version>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.sb">
            <summary>
            Buffer for the terms while stemming them.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.tb">
            <summary>
            A temporary buffer, used to reconstruct R2
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.R0">
            <summary>
            Region R0 is equal to the whole buffer
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.RV">
            <summary>
            Region RV
            "If the word begins with two vowels, RV is the region after the third letter,
            otherwise the region after the first vowel not at the beginning of the word,
            or the end of the word if these positions cannot be found."
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.R1">
            <summary>
            Region R1
            "R1 is the region after the first non-vowel following a vowel
            or is the null region at the end of the word if there is no such non-vowel"
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.R2">
            <summary>
            Region R2
            "R2 is the region after the first non-vowel in R1 following a vowel
            or is the null region at the end of the word if there is no such non-vowel"
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.suite">
            <summary>
            Set to true if we need to perform step 2
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Fr.FrenchStemmer.modified">
            <summary>
            Set to true if the buffer was modified
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Stem(System.String)">
            <summary>
            Stemms the given term to a unique <tt>discriminator</tt>.
            </summary>
            <param name="term">
            java.langString The term that should be stemmed
            </param>
            <returns>
            Discriminator for <tt>term</tt>
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.SetStrings">
            <summary>
            Sets the search region Strings<br/>
            it needs to be done each time the buffer was modified
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step1">
            <summary>
            First step of the Porter Algorithmn<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step2a">
            <summary>
            Second step (A) of the Porter Algorithmn<br/>
            Will be performed if nothing changed from the first step
            or changed were done in the amment, emment, ments or ment suffixes<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
            <returns>
            true if something changed in the StringBuilder
            </returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step2b">
            <summary>
            Second step (B) of the Porter Algorithmn<br/>
            Will be performed if step 2 A was performed unsuccessfully<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step3">
            <summary>
            Third step of the Porter Algorithmn<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step4">
            <summary>
            Fourth step of the Porter Algorithmn<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step5">
            <summary>
            Fifth step of the Porter Algorithmn<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.Step6">
            <summary>
            Sixth (and last!) step of the Porter Algorithmn<br/>
            refer to http://snowball.sourceforge.net/french/stemmer.html for an explanation
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.DeleteFromIfPrecededIn(System.String,System.String[],System.String,System.String)">
            <summary>
            Delete a suffix searched in zone "source" if zone "from" contains prefix + search string
            </summary>
            <param name="source">the primary source zone for search</param>
            <param name="search">the strings to search for suppression</param>
            <param name="from">the secondary source zone for search</param>
            <param name="prefix">the prefix to add to the search string to test</param>
            <returns>true if modified</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.DeleteFromIfTestVowelBeforeIn(System.String,System.String[],System.Boolean,System.String)">
            <summary>
            Delete a suffix searched in zone "source" if the preceding letter is (or isn't) a vowel
            </summary>
            <param name="source">the primary source zone for search</param>
            <param name="search">the strings to search for suppression</param>
            <param name="vowel">true if we need a vowel before the search string</param>
            <param name="from">the secondary source zone for search (where vowel could be)</param>
            <returns>true if modified</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.DeleteButSuffixFrom(System.String,System.String[],System.String,System.Boolean)">
            <summary>
            Delete a suffix searched in zone "source" if preceded by the prefix
            </summary>
            <param name="source">the primary source zone for search</param>
            <param name="search">the strings to search for suppression</param>
            <param name="prefix">the prefix to add to the search string to test</param>
            <param name="without">true if it will be deleted even without prefix found</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.DeleteButSuffixFromElseReplace(System.String,System.String[],System.String,System.Boolean,System.String,System.String)">
            <summary>
            Delete a suffix searched in zone "source" if preceded by prefix<br/>
            or replace it with the replace string if preceded by the prefix in the zone "from"<br/>
            or delete the suffix if specified
            </summary>
            <param name="source">the primary source zone for search</param>
            <param name="search">the strings to search for suppression</param>
            <param name="prefix">the prefix to add to the search string to test</param>
            <param name="without">true if it will be deleted even without prefix found</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.ReplaceFrom(System.String,System.String[],System.String)">
            <summary>
            Replace a search string with another within the source zone
            </summary>
            <param name="source">the source zone for search</param>
            <param name="search">the strings to search for replacement</param>
            <param name="replace">the replacement string</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.DeleteFrom(System.String,System.String[])">
            <summary>
            Delete a search string within the source zone
            </summary>
            <param name="source">the source zone for search</param>
            <param name="suffix">the strings to search for suppression</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.IsVowel(System.Char)">
            <summary>
            Test if a char is a french vowel, including accentuated ones
            </summary>
            <param name="ch">the char to test</param>
            <returns>true if the char is a vowel</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.RetrieveR(System.Text.StringBuilder)">
            <summary>
            Retrieve the "R zone" (1 or 2 depending on the buffer) and return the corresponding string<br/>
            "R is the region after the first non-vowel following a vowel
            or is the null region at the end of the word if there is no such non-vowel"<br/>
            </summary>
            <param name="buffer">the in buffer</param>
            <returns>the resulting string</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.RetrieveRV(System.Text.StringBuilder)">
            <summary>
            Retrieve the "RV zone" from a buffer an return the corresponding string<br/>
            "If the word begins with two vowels, RV is the region after the third letter,
            otherwise the region after the first vowel not at the beginning of the word,
            or the end of the word if these positions cannot be found."<br/>
            </summary>
            <param name="buffer">the in buffer</param>
            <returns>the resulting string</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.TreatVowels(System.Text.StringBuilder)">
            <summary>
            Turns u and i preceded AND followed by a vowel to UpperCase<br/>
            Turns y preceded OR followed by a vowel to UpperCase<br/>
            Turns u preceded by q to UpperCase<br/>
            </summary>
            <param name="buffer">the buffer to treat</param>
            <returns>the treated buffer</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Fr.FrenchStemmer.IsStemmable(System.String)">
            <summary>
            Checks a term if it can be processed correctly.
            </summary>
            <returns>true if, and only if, the given term consists in letters.</returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Miscellaneous.PrefixAwareTokenFilter">
            <summary>
            Joins two token streams and leaves the last token of the first stream available
            to be used when updating the token values in the second stream based on that token.
            
            The default implementation adds last prefix token end offset to the suffix token start and end offsets.
            <p/>
            <b>NOTE:</b> This filter might not behave correctly if used with custom Attributes, i.e. Attributes other than
            the ones located in Lucene.Net.Analysis.TokenAttributes. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.PrefixAwareTokenFilter.Next(Lucene.Net.Analysis.Token)">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer.
            </summary>
            <param name="reusableToken"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.PrefixAwareTokenFilter.Next">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.PrefixAwareTokenFilter.UpdateSuffixToken(Lucene.Net.Analysis.Token,Lucene.Net.Analysis.Token)">
            <summary>
            The default implementation adds last prefix token end offset to the suffix token start and end offsets.
            </summary>
            <param name="suffixToken">a token from the suffix stream</param>
            <param name="lastPrefixToken">the last token from the prefix stream</param>
            <returns>consumer token</returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Miscellaneous.PrefixAndSuffixAwareTokenFilter">
            <summary>
            Links two PrefixAwareTokenFilter.
            <p/>
            <b>NOTE:</b> This filter might not behave correctly if used with custom Attributes, i.e. Attributes other than
            the ones located in Lucene.Net.Analysis.Tokenattributes.  
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.PrefixAndSuffixAwareTokenFilter.Next(Lucene.Net.Analysis.Token)">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer. 
            </summary>
            <param name="reusableToken"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.PrefixAndSuffixAwareTokenFilter.Next">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer. 
            </summary>
        </member>
        <member name="T:Lucene.Net.Analyzers.Miscellaneous.SingleTokenTokenStream">
            <summary>
            A TokenStream containing a single token.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.SingleTokenTokenStream.Next(Lucene.Net.Analysis.Token)">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer.
            </summary>
            <param name="reusableToken"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Miscellaneous.SingleTokenTokenStream.Next">
            <summary>
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer. 
            </summary>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter">
            Tokenizes the given token into n-grams of given size(s).
            <p>
            This <see cref="T:Lucene.Net.Analysis.TokenFilter"/> create n-grams from the beginning edge or ending edge of a input token.
            </p>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.#ctor(Lucene.Net.Analysis.TokenStream,Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side,System.Int32,System.Int32)">
             Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range
            
             <param name="input"><see cref="T:Lucene.Net.Analysis.TokenStream"/> holding the input to be tokenized</param>
             <param name="side">the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.String,System.Int32,System.Int32)">
             Creates EdgeNGramTokenFilter that can generate n-grams in the sizes of the given range
            
             <param name="input"><see cref="T:Lucene.Net.Analysis.TokenStream"/> holding the input to be tokenized</param>
             <param name="sideLabel">the name of the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Next(Lucene.Net.Analysis.Token)">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Next">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side">
            Specifies which side of the input the n-gram should be generated from 
        </member>
        <member name="F:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side.FRONT">
            Get the n-gram from the front of the input 
        </member>
        <member name="F:Lucene.Net.Analysis.NGram.EdgeNGramTokenFilter.Side.BACK">
            Get the n-gram from the end of the input 
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer">
            Tokenizes the input from an edge into n-grams of given size(s).
            <p>
            This <see cref="T:Lucene.Net.Analysis.Tokenizer"/> create n-grams from the beginning edge or ending edge of a input token.
            MaxGram can't be larger than 1024 because of limitation.
            </p>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(System.IO.TextReader,Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side,System.Int32,System.Int32)">
             Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
             <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
             <param name="side">the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader,Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side,System.Int32,System.Int32)">
             Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
             <param name="source"><see cref="T:Lucene.Net.Util.AttributeSource"/> to use</param>
             <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
             <param name="side">the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader,Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side,System.Int32,System.Int32)">
            Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
            <param name="factory"><see cref="T:Lucene.Net.Util.AttributeSource.AttributeFactory"/> to use</param>
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
            <param name="side">the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(System.IO.TextReader,System.String,System.Int32,System.Int32)">
             Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
             <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
             <param name="sideLabel">the name of the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader,System.String,System.Int32,System.Int32)">
             Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
             <param name="source"><see cref="T:Lucene.Net.Util.AttributeSource"/> to use</param>
             <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
             <param name="sideLabel">the name of the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
             <param name="minGram">the smallest n-gram to generate</param>
             <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader,System.String,System.Int32,System.Int32)">
            Creates EdgeNGramTokenizer that can generate n-grams in the sizes of the given range
            
            <param name="factory"><see cref="T:Lucene.Net.Util.AttributeSource.AttributeFactory"/> to use</param>
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
            <param name="sideLabel">the name of the <see cref="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side"/> from which to chop off an n-gram</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.IncrementToken">
            Returns the next token in the stream, or null at EOS. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Next(Lucene.Net.Analysis.Token)">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Next">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side">
            Specifies which side of the input the n-gram should be generated from 
        </member>
        <member name="F:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side.FRONT">
            Get the n-gram from the front of the input 
        </member>
        <member name="F:Lucene.Net.Analysis.NGram.EdgeNGramTokenizer.Side.BACK">
            Get the n-gram from the end of the input 
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.NGramTokenFilter">
            Tokenizes the input into n-grams of the given size(s).
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32)">
            Creates NGramTokenFilter with given min and max n-grams.
            <param name="input"><see cref="T:Lucene.Net.Analysis.TokenStream"/> holding the input to be tokenized</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenFilter.#ctor(Lucene.Net.Analysis.TokenStream)">
            Creates NGramTokenFilter with default min and max n-grams.
            <param name="input"><see cref="T:Lucene.Net.Analysis.TokenStream"/> holding the input to be tokenized</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenFilter.IncrementToken">
            Returns the next token in the stream, or null at EOS. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenFilter.Next(Lucene.Net.Analysis.Token)">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenFilter.Next">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="T:Lucene.Net.Analysis.NGram.NGramTokenizer">
            Tokenizes the input into n-grams of the given size(s).
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(System.IO.TextReader,System.Int32,System.Int32)">
            Creates NGramTokenizer with given min and max n-grams.
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource,System.IO.TextReader,System.Int32,System.Int32)">
            Creates NGramTokenizer with given min and max n-grams.
            <param name="source"><see cref="T:Lucene.Net.Util.AttributeSource"/> to use</param>
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(Lucene.Net.Util.AttributeSource.AttributeFactory,System.IO.TextReader,System.Int32,System.Int32)">
            Creates NGramTokenizer with given min and max n-grams.
            <param name="factory"><see cref="T:Lucene.Net.Util.AttributeSource.AttributeFactory"/> to use</param>
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
            <param name="minGram">the smallest n-gram to generate</param>
            <param name="maxGram">the largest n-gram to generate</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.#ctor(System.IO.TextReader)">
            Creates NGramTokenizer with default min and max n-grams.
            <param name="input"><see cref="T:System.IO.TextReader"/> holding the input to be tokenized</param>
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.IncrementToken">
            Returns the next token in the stream, or null at EOS. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.Next(Lucene.Net.Analysis.Token)">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="M:Lucene.Net.Analysis.NGram.NGramTokenizer.Next">
            @deprecated Will be removed in Lucene 3.0. This method is final, as it should
            not be overridden. Delegates to the backwards compatibility layer. 
        </member>
        <member name="T:Lucene.Net.Analysis.Nl.DutchAnalyzer">
            <summary>
            Analyzer for Dutch language. Supports an external list of stopwords (words that
            will not be indexed at all), an external list of exclusions (word that will
            not be stemmed, but indexed) and an external list of word-stem pairs that overrule
            the algorithm (dictionary stemming).
            A default set of stopwords is used unless an alternative list is specified, the
            exclusion list is empty by default. 
            <version>$Id: DutchAnalyzer.java,v 1.1 2004/03/09 14:55:08 otis Exp $</version>
            </summary>
            <author>Edwin de Jonge</author>
        </member>
        <member name="F:Lucene.Net.Analysis.Nl.DutchAnalyzer.DUTCH_STOP_WORDS">
            <summary>
            List of typical german stopwords.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Nl.DutchAnalyzer.stoptable">
            <summary>
            Contains the stopwords used with the StopFilter. 
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Nl.DutchAnalyzer.excltable">
            <summary>
            Contains words that should be indexed but not stemmed. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.#ctor">
            <summary>
            Builds an analyzer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.#ctor(System.String[])">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.#ctor(System.Collections.Hashtable)">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.#ctor(System.IO.FileInfo)">
            <summary>
            Builds an analyzer with the given stop words. 
            </summary>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.SetStemExclusionTable(System.String[])">
            <summary>
            Builds an exclusionlist from an array of Strings. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.SetStemExclusionTable(System.Collections.Hashtable)">
            <summary>
            Builds an exclusionlist from a Hashtable. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.SetStemExclusionTable(System.IO.FileInfo)">
            <summary>
            Builds an exclusionlist from the words contained in the given file. 
            </summary>
            <param name="exclusionlist"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.SetStemDictionary(System.IO.FileInfo)">
            <summary>
            Reads a stemdictionary file , that overrules the stemming algorithm
            This is a textfile that contains per line
            word\tstem
            i.e: tabseperated
            </summary>
            <param name="stemdict"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided TextReader. 
            </summary>
            <param name="fieldName"></param>
            <param name="reader"></param>
            <returns>A TokenStream build from a StandardTokenizer filtered with StandardFilter, StopFilter, GermanStemFilter</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Nl.DutchStemFilter">
            <summary>
            A filter that stems Dutch words. It supports a table of words that should
            not be stemmed at all. The stemmer used can be changed at runtime after the
            filter object is created (as long as it is a DutchStemmer).
            
            <version>$Id: DutchStemFilter.java,v 1.1 2004/03/09 14:55:08 otis Exp $</version>
            </summary>
            <author>Edwin de Jonge</author>
        </member>
        <member name="F:Lucene.Net.Analysis.Nl.DutchStemFilter.token">
            <summary>
            The actual token in the input stream.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable)">
            <summary>
            Builds a DutchStemFilter that uses an exclusiontable. 
            </summary>
            <param name="_in"></param>
            <param name="exclusiontable"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Collections.Hashtable,System.Collections.Hashtable)">
            <summary>
            
            </summary>
            <param name="_in"></param>
            <param name="exclusiontable"></param>
            <param name="stemdictionary">Dictionary of word stem pairs, that overrule the algorithm</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.Next">
            <summary>
            </summary>
            <returns>Returns the next token in the stream, or null at EOS</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.SetStemmer(Lucene.Net.Analysis.Nl.DutchStemmer)">
            <summary>
            Set a alternative/custom DutchStemmer for this filter. 
            </summary>
            <param name="stemmer"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.SetExclusionTable(System.Collections.Hashtable)">
            <summary>
            Set an alternative exclusion list for this filter. 
            </summary>
            <param name="exclusiontable"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemFilter.SetStemDictionary(System.Collections.Hashtable)">
            <summary>
            Set dictionary for stemming, this dictionary overrules the algorithm,
            so you can correct for a particular unwanted word-stem pair.
            </summary>
            <param name="dict"></param>
        </member>
        <member name="T:Lucene.Net.Analysis.Nl.DutchStemmer">
            <summary>
            A stemmer for Dutch words. The algorithm is an implementation of
            the <see c="http://snowball.tartarus.org/dutch/stemmer.html">dutch stemming</see>
            algorithm in snowball. Snowball is a project of Martin Porter (does Porter Stemmer ring a bell?): 
            
            @version   $Id: DutchStemmer.java,v 1.1 2004/03/09 14:55:08 otis Exp $
            </summary>
            <author>Edwin de Jonge (ejne@cbs.nl)</author>
        </member>
        <member name="F:Lucene.Net.Analysis.Nl.DutchStemmer.sb">
            <summary>
            Buffer for the terms while stemming them. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Stem(System.String)">
            <summary>
            Stemms the given term to an unique <tt>discriminator</tt>.
            </summary>
            <param name="term">The term that should be stemmed.</param>
            <returns>Discriminator for <tt>term</tt></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Step2(System.Text.StringBuilder)">
            <summary>
            Delete suffix e if in R1 and 
            preceded by a non-vowel, and then undouble the ending
            </summary>
            <param name="sb">string being stemmed</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Step3a(System.Text.StringBuilder)">
            <summary>
            Delete "heid"
            </summary>
            <param name="sb">string being stemmed</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Step3b(System.Text.StringBuilder)">
            <summary>
            <p>A d-suffix, or derivational suffix, enables a new word, 
            often with a different grammatical category, or with a different 
            sense, to be built from another word. Whether a d-suffix can be 
            attached is discovered not from the rules of grammar, but by 
            referring to a dictionary. So in English, ness can be added to 
            certain adjectives to form corresponding nouns (littleness, 
            kindness, foolishness ...) but not to all adjectives 
            (not for example, to big, cruel, wise ...) d-suffixes can be 
            used to change meaning, often in rather exotic ways.</p>
            Remove "ing", "end", "ig", "lijk", "baar" and "bar"
            </summary>
            <param name="sb">string being stemmed</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Step4(System.Text.StringBuilder)">
            <summary>
            undouble vowel 
            If the words ends CVD, where C is a non-vowel, D is a non-vowel other than I, and V is double a, e, o or u, remove one of the vowels from V (for example, maan -> man, brood -> brod). 
            </summary>
            <param name="sb">string being stemmed</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.IsStemmable(System.String)">
            <summary>
            Checks if a term could be stemmed.
            </summary>
            <param name="term"></param>
            <returns>true if, and only if, the given term consists in letters.</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.DutchStemmer.Substitute(System.Text.StringBuilder)">
            <summary>
            Substitute ä, ë, ï, ö, ü, á , é, í, ó, ú
            </summary>
            <param name="buffer"></param>
        </member>
        <member name="T:Lucene.Net.Analysis.Nl.WordlistLoader">
            <summary>
            Loads a text file and adds every line as an entry to a Hashtable. Every line
            should contain only one word. If the file is not found or on any error, an
            empty table is returned.
            
            <version>$Id: WordListLoader.java,v 1.1 2004/03/09 14:55:08 otis Exp $</version>
            </summary>
            <author>Gerhard Schwarz</author>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.WordlistLoader.GetWordtable(System.String,System.String)">
            <param name="path">Path to the wordlist</param>
            <param name="wordfile">Name of the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.WordlistLoader.GetWordtable(System.String)">
            <param name="wordfile">Complete path to the wordlist</param>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.WordlistLoader.GetStemDict(System.IO.FileInfo)">
            <summary>
            Reads a stemsdictionary. Each line contains: 
            word \t stem 
            (i.e. tab seperated)
            </summary>
            <param name="wordstemfile"></param>
            <returns>Stem dictionary that overrules, the stemming algorithm</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.WordlistLoader.GetWordtable(System.IO.FileInfo)">
            <summary>
            
            </summary>
            <param name="wordfile">File containing the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Nl.WordlistLoader.MakeWordTable(System.String[],System.Int32)">
            <summary>
            Builds the wordlist table.
            </summary>
            <param name="words">Word that where read</param>
            <param name="length">Amount of words that where read into <tt>words</tt></param>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Payloads.PayloadHelper">
            <summary>
            Utility methods for encoding payloads.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Payloads.PayloadHelper.DecodeFloat(System.Byte[])">
            <summary>
            <p>Decode the payload that was encoded using encodeFloat(float)</p>
            <p>NOTE: the length of the array must be at least offset + 4 long.</p>
            </summary>
            <param name="bytes">The bytes to decode</param>
            <returns>the decoded float</returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Payloads.PayloadHelper.DecodeFloat(System.Byte[],System.Int32)">
            <summary>
            <p>Decode the payload that was encoded using encodeFloat(float)</p>
            <p>NOTE: the length of the array must be at least offset + 4 long.</p>
            </summary>
            <param name="bytes">The bytes to decode</param>
            <param name="offset">The offset into the array.</param>
            <returns>The float that was encoded</returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianAnalyzer">
            <summary>
            Analyzer for Russian language. Supports an external list of stopwords (words that
            will not be indexed at all).
            A default set of stopwords is used unless an alternative list is specified.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianAnalyzer.RUSSIAN_STOP_WORDS">
            <summary>
            List of typical Russian stopwords.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianAnalyzer.stoptable">
            <summary>
            Contains the stopwords used with the StopFilter.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianAnalyzer.charset">
            <summary>
            Charset for Russian letters.
            Represents encoding for 32 lowercase Russian letters.
            Predefined charsets can be taken from RussianCharSets class
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.#ctor">
            <summary>
            Builds an analyzer.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.#ctor(System.Char[])">
            <summary>
            Builds an analyzer.
            </summary>
            <param name="charset"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.#ctor(System.Char[],System.String[])">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
            <param name="charset"></param>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.MakeStopWords(System.Char[])">
            <summary>
            Takes russian stop words and translates them to a String array, using
            the given charset 
            </summary>
            <param name="charset"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.#ctor(System.Char[],System.Collections.Hashtable)">
            <summary>
            Builds an analyzer with the given stop words.
            </summary>
            <param name="charset"></param>
            <param name="stopwords"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianAnalyzer.TokenStream(System.String,System.IO.TextReader)">
            <summary>
            Creates a TokenStream which tokenizes all the text in the provided TextReader.
            </summary>
            <param name="fieldName"></param>
            <param name="reader"></param>
            <returns>
            	A TokenStream build from a RussianLetterTokenizer filtered with
                RussianLowerCaseFilter, StopFilter, and RussianStemFilter
             </returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianCharsets">
            <summary>
            RussianCharsets class contains encodings schemes (charsets) and ToLowerCase() method implementation
            for russian characters in Unicode, KOI8 and CP1252.
            Each encoding scheme contains lowercase (positions 0-31) and uppercase (position 32-63) characters.
            One should be able to add other encoding schemes (like ISO-8859-5 or customized) by adding a new charset
            and adding logic to ToLowerCase() method for that charset.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianCharsets.UnicodeRussian">
            <summary>
            Unicode Russian charset (lowercase letters only)
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianCharsets.KOI8">
            <summary>
            KOI8 charset
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianCharsets.CP1251">
            <summary>
            CP1251 Charset
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianLetterTokenizer">
            <summary>
            A RussianLetterTokenizer is a tokenizer that extends LetterTokenizer by additionally looking up letters
            in a given "russian charset". The problem with LeterTokenizer is that it uses Character.isLetter() method,
            which doesn't know how to detect letters in encodings like CP1252 and KOI8
            (well-known problems with 0xD7 and 0xF7 chars)
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianLetterTokenizer.charset">
            <summary>
            Construct a new LetterTokenizer.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianLetterTokenizer.IsTokenChar(System.Char)">
            <summary>
            Collects only characters which satisfy Char.IsLetter(char).
            </summary>
            <param name="c"></param>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianLowerCaseFilter">
            <summary>
            Normalizes token text to lower case, analyzing given ("russian") charset.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianStemFilter">
            <summary>
            A filter that stems Russian words. The implementation was inspired by GermanStemFilter.
            The input should be filtered by RussianLowerCaseFilter before passing it to RussianStemFilter,
            because RussianStemFilter only works  with lowercase part of any "russian" charset.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemFilter.token">
            <summary>
            The actual token in the input stream.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemFilter.Next">
            <summary>
            
            </summary>
            <returns>Returns the next token in the stream, or null at EOS</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemFilter.SetStemmer(Lucene.Net.Analysis.Ru.RussianStemmer)">
            <summary>
            Set a alternative/custom RussianStemmer for this filter.
            </summary>
            <param name="stemmer"></param>
        </member>
        <member name="T:Lucene.Net.Analysis.Ru.RussianStemmer">
            <summary>
            Russian stemming algorithm implementation (see http://snowball.sourceforge.net for detailed description).
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemmer.RV">
            <summary>
            positions of RV, R1 and R2 respectively
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemmer.R1">
            <summary>
            positions of RV, R1 and R2 respectively
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemmer.R2">
            <summary>
            positions of RV, R1 and R2 respectively
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemmer.A">
            <summary>
            letters
            </summary>
        </member>
        <member name="F:Lucene.Net.Analysis.Ru.RussianStemmer.vowels">
            <summary>
            stem definitions
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.#ctor">
            <summary>
            RussianStemmer constructor comment.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.#ctor(System.Char[])">
            <summary>
            RussianStemmer constructor comment.
            </summary>
            <param name="charset"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Adjectival(System.Text.StringBuilder)">
            <summary>
            Adjectival ending is an adjective ending,
            optionally preceded by participle ending.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone">StringBuilder</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Derivational(System.Text.StringBuilder)">
            <summary>
            Derivational endings
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone">StringBuilder</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.FindEnding(System.Text.StringBuilder,System.Int32,System.Char[][])">
            <summary>
            Finds ending among given ending class and returns the length of ending found(0, if not found).
            Creation date: (17/03/2002 8:18:34 PM)
            </summary>
            <param name="stemmingZone"></param>
            <param name="startIndex"></param>
            <param name="theEndingClass"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.FindAndRemoveEnding(System.Text.StringBuilder,System.Char[][])">
            <summary>
            Finds the ending among the given class of endings and removes it from stemming zone.
            Creation date: (17/03/2002 8:18:34 PM)
            </summary>
            <param name="stemmingZone"></param>
            <param name="theEndingClass"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.FindAndRemoveEnding(System.Text.StringBuilder,System.Char[][],System.Char[][])">
            <summary>
            Finds the ending among the given class of endings, then checks if this ending was
            preceded by any of given predessors, and if so, removes it from stemming zone.
            Creation date: (17/03/2002 8:18:34 PM)
            </summary>
            <param name="stemmingZone"></param>
            <param name="theEndingClass"></param>
            <param name="thePredessors"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.MarkPositions(System.String)">
            <summary>
            Marks positions of RV, R1 and R2 in a given word.
            Creation date: (16/03/2002 3:40:11 PM)
            </summary>
            <param name="word"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.IsVowel(System.Char)">
            <summary>
            Checks if character is a vowel..
            Creation date: (16/03/2002 10:47:03 PM)
            </summary>
            <param name="letter"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Noun(System.Text.StringBuilder)">
            <summary>
            Noun endings.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.PerfectiveGerund(System.Text.StringBuilder)">
            <summary>
            Perfective gerund endings.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Reflexive(System.Text.StringBuilder)">
            <summary>
            Reflexive endings.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.RemoveI(System.Text.StringBuilder)">
            <summary>
            Insert the method's description here.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.RemoveSoft(System.Text.StringBuilder)">
            <summary>
            Insert the method's description here.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.SetCharset(System.Char[])">
            <summary>
            Insert the method's description here.
            Creation date: (16/03/2002 10:58:42 PM)
            </summary>
            <param name="newCharset"></param>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Stem(System.String)">
            <summary>
            Finds the stem for given Russian word.
            Creation date: (16/03/2002 3:36:48 PM)
            </summary>
            <param name="input"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Superlative(System.Text.StringBuilder)">
            <summary>
            Superlative endings.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.UndoubleN(System.Text.StringBuilder)">
            <summary>
            Undoubles N.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Verb(System.Text.StringBuilder)">
            <summary>
            Verb endings.
            Creation date: (17/03/2002 12:14:58 AM)
            </summary>
            <param name="stemmingZone"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.Ru.RussianStemmer.Stem(System.String,System.Char[])">
            <summary>
            Static method for stemming with different charsets
            </summary>
            <param name="theWord"></param>
            <param name="charset"></param>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.Matrix.Matrix">
            <summary>
            A column focused matrix in three dimensions:
            
            <pre>
            Token[column][row][z-axis] {
                {{hello}, {greetings, and, salutations}},
                {{world}, {earth}, {tellus}}
            };
            </pre>
            
            todo consider row groups
            to indicate that shingles is only to contain permutations with texts in that same row group.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.ShingleAnalyzerWrapper">
            <summary>
            A ShingleAnalyzerWrapper wraps a ShingleFilter around another Analyzer.
            
            <p>A shingle is another name for a token based n-gram.</p>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleAnalyzerWrapper.#ctor">
            <summary>
            Wraps StandardAnalyzer. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleAnalyzerWrapper.GetMaxShingleSize">
            <summary>
            The max shingle (ngram) size
            </summary>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleAnalyzerWrapper.SetMaxShingleSize(System.Int32)">
            <summary>
            Set the maximum size of output shingles
            </summary>
            <param name="maxShingleSize">max shingle size</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleAnalyzerWrapper.SetOutputUnigrams(System.Boolean)">
            <summary>
            Shall the filter pass the original tokens (the "unigrams") to the output
            stream?
            </summary>
            <param name="outputUnigrams">Whether or not the filter shall pass the original tokens to the output stream</param>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.ShingleFilter">
            <summary>
            <p>A ShingleFilter constructs shingles (token n-grams) from a token stream.
            In other words, it creates combinations of tokens as a single token.</p>
            
            <p>For example, the sentence "please divide this sentence into shingles"
            might be tokenized into shingles "please divide", "divide this",
            "this sentence", "sentence into", and "into shingles".</p>
                
            <p>This filter handles position increments > 1 by inserting filler tokens
            (tokens with termtext "_"). It does not handle a position increment of 0. </p>
            </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleFilter.FillerToken">
            <summary>
            Filler token for when positionIncrement is more than 1
            </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleFilter.DefaultMaxShingleSize">
            <summary>
            Default maximum shingle size is 2.
            </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleFilter.TokenSeparator">
            <summary>
            The string to use when joining adjacent tokens to form a shingle
            </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleFilter._maxShingleSize">
            <summary>
            Maximum shingle size (number of tokens)
            </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleFilter._outputUnigrams">
            <summary>
            By default, we output unigrams (individual tokens) as well as shingles (token n-grams).
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32)">
            <summary>
            Constructs a ShingleFilter with the specified single size from the TokenStream
            </summary>
            <param name="input">input token stream</param>
            <param name="maxShingleSize">maximum shingle size produced by the filter.</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.#ctor(Lucene.Net.Analysis.TokenStream)">
            <summary>
            Construct a ShingleFilter with default shingle size.
            </summary>
            <param name="input">input stream</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.String)">
            <summary>
            Construct a ShingleFilter with the specified token type for shingle tokens.
            </summary>
            <param name="input">input stream</param>
            <param name="tokenType">token type for shingle tokens</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.SetTokenType(System.String)">
            <summary>
            Set the type of the shingle tokens produced by this filter. (default: "shingle")
            </summary>
            <param name="tokenType">token TokenType</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.SetOutputUnigrams(System.Boolean)">
            <summary>
            Shall the output stream contain the input tokens (unigrams) as well as shingles? (default: true.)
            </summary>
            <param name="outputUnigrams">Whether or not the output stream shall contain the input tokens (unigrams)</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.SetMaxShingleSize(System.Int32)">
            <summary>
            Set the max shingle size (default: 2)
            </summary>
            <param name="maxShingleSize">max size of output shingles</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.ClearShingles">
            <summary>
            Clear the StringBuilders that are used for storing the output shingles.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.IncrementToken">
            <summary>
            See Lucene.Net.Analysis.TokenStream.Next()
            </summary>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.GetNextToken">
            <summary>
            <p>
            Get the next token from the input stream and push it on the token buffer.
            If we encounter a token with position increment > 1, we put filler tokens
            on the token buffer.
            </p>
            Returns null when the end of the input stream is reached.
            </summary>
            <returns>the next token, or null if at end of input stream</returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.FillShingleBuffer">
            <summary>
            Fill the output buffer with new shingles.
            </summary>
            <exception cref="T:System.IO.IOException">throws IOException if there's a problem getting the next token</exception>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.Next(Lucene.Net.Analysis.Token)">
            <summary>
            Deprecated: Will be removed in Lucene 3.0. This method is readonly, as it should not be overridden. 
            Delegates to the backwards compatibility layer.
            </summary>
            <param name="reusableToken"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleFilter.Next">
            <summary>
            Deprecated: Will be removed in Lucene 3.0. This method is readonly, as it should not be overridden. 
            Delegates to the backwards compatibility layer.
            </summary>
            <returns></returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter">
             <summary>
             <p>A ShingleMatrixFilter constructs shingles (token n-grams) from a token stream.
             In other words, it creates combinations of tokens as a single token.</p>
            
             <p>For example, the sentence "please divide this sentence into shingles"
             might be tokenized into shingles "please divide", "divide this",
             "this sentence", "sentence into", and "into shingles".</p>
            
             <p>Using a shingle filter at index and query time can in some instances
             be used to replace phrase queries, especially them with 0 slop.</p>
            
             <p>Without a spacer character
             it can be used to handle composition and decomposition of words
             such as searching for "multi dimensional" instead of "multidimensional".
             It is a rather common human problem at query time
             in several languages, notably the northern Germanic branch.</p>
            
             <p>Shingles are amongst many things also known to solve problems
             in spell checking, language detection and document clustering.</p>
            
             <p>This filter is backed by a three dimensional column oriented matrix
             used to create permutations of the second dimension, the rows,
             and leaves the third, the z-axis, for for multi token synonyms.</p>
            
             <p>In order to use this filter you need to define a way of positioning
             the input stream tokens in the matrix. This is done using a
             ShingleMatrixFilter.TokenSettingsCodec.
             There are three simple implementations for demonstrational purposes,
             see ShingleMatrixFilter.OneDimensionalNonWeightedTokenSettingsCodec,
             ShingleMatrixFilter.TwoDimensionalNonWeightedSynonymTokenSettingsCodec
             and ShingleMatrixFilter.SimpleThreeDimensionalTokenSettingsCodec.</p>
            
             <p>Consider this token matrix:</p>
             <pre>
              Token[column][row][z-axis]{
                {{hello}, {greetings, and, salutations}},
                {{world}, {earth}, {tellus}}
              };
             </pre>
            
             It would produce the following 2-3 gram sized shingles:
            
             <pre>
             "hello_world"
             "greetings_and"
             "greetings_and_salutations"
             "and_salutations"
             "and_salutations_world"
             "salutations_world"
             "hello_earth"
             "and_salutations_earth"
             "salutations_earth"
             "hello_tellus"
             "and_salutations_tellus"
             "salutations_tellus"
              </pre>
            
             <p>This implementation can be rather heap demanding
             if (maximum shingle size - minimum shingle size) is a great number and the stream contains many columns,
             or if each column contains a great number of rows.</p>
            
             <p>The problem is that in order avoid producing duplicates
             the filter needs to keep track of any shingle already produced and returned to the consumer.</p>
            
             <p>There is a bit of resource management to handle this
             but it would of course be much better if the filter was written
             so it never created the same shingle more than once in the first place.</p>
            
             <p>The filter also has basic support for calculating weights for the shingles
             based on the weights of the tokens from the input stream, output shingle size, etc.
             See CalculateShingleWeight.
             <p/>
             <b>NOTE:</b> This filter might not behave correctly if used with custom Attributes, i.e. Attributes other than
             the ones located in org.apache.lucene.analysis.tokenattributes.</p> 
             </summary>
        </member>
        <member name="F:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter._shinglesSeen">
            <summary>
            A set containing shingles that has been the result of a call to Next(Token),
            used to avoid producing the same shingle more than once.
            
            <p>
            NOTE: The Java List implementation uses a different equality comparison scheme
            than .NET's Generic List. So We have to use a custom IEqualityComparer implementation 
            to get the same behaviour.
            </p>
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.#ctor(Lucene.Net.Analyzers.Shingle.Matrix.Matrix,System.Int32,System.Int32,System.Char,System.Boolean,Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec)">
            <summary>
            Creates a shingle filter based on a user defined matrix.
            
            The filter /will/ delete columns from the input matrix! You will not be able to reset the filter if you used this constructor.
            todo: don't touch the matrix! use a bool, set the input stream to null or something, and keep track of where in the matrix we are at.
            
            </summary>
            <param name="matrix">the input based for creating shingles. Does not need to contain any information until ShingleMatrixFilter.Next(Token) is called the first time.</param>
            <param name="minimumShingleSize">minimum number of tokens in any shingle.</param>
            <param name="maximumShingleSize">maximum number of tokens in any shingle.</param>
            <param name="spacerCharacter">character to use between texts of the token parts in a shingle. null for none.</param>
            <param name="ignoringSinglePrefixOrSuffixShingle">if true, shingles that only contains permutation of the first of the last column will not be produced as shingles. Useful when adding boundary marker tokens such as '^' and '$'.</param>
            <param name="settingsCodec">codec used to read input token weight and matrix positioning.</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32)">
            <summary>
            Creates a shingle filter using default settings.
            
            See ShingleMatrixFilter.DefaultSpacerCharacter, 
            ShingleMatrixFilter.IgnoringSinglePrefixOrSuffixShingleByDefault, 
            and ShingleMatrixFilter.DefaultSettingsCodec
            </summary>
            <param name="input">stream from which to construct the matrix</param>
            <param name="minimumShingleSize">minimum number of tokens in any shingle.</param>
            <param name="maximumShingleSize">maximum number of tokens in any shingle.</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32,System.Nullable{System.Char})">
            <summary>
            Creates a shingle filter using default settings.
            
            See IgnoringSinglePrefixOrSuffixShingleByDefault, and DefaultSettingsCodec
            </summary>
            <param name="input">stream from which to construct the matrix</param>
            <param name="minimumShingleSize">minimum number of tokens in any shingle.</param>
            <param name="maximumShingleSize">maximum number of tokens in any shingle.</param>
            <param name="spacerCharacter">character to use between texts of the token parts in a shingle. null for none. </param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32,System.Nullable{System.Char},System.Boolean)">
            <summary>
            Creates a shingle filter using the default <see cref="T:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec"/>.
            
            See DefaultSettingsCodec
            </summary>
            <param name="input">stream from which to construct the matrix</param>
            <param name="minimumShingleSize">minimum number of tokens in any shingle.</param>
            <param name="maximumShingleSize">maximum number of tokens in any shingle.</param>
            <param name="spacerCharacter">character to use between texts of the token parts in a shingle. null for none.</param>
            <param name="ignoringSinglePrefixOrSuffixShingle">if true, shingles that only contains permutation of the first of the last column will not be produced as shingles. Useful when adding boundary marker tokens such as '^' and '$'.</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.#ctor(Lucene.Net.Analysis.TokenStream,System.Int32,System.Int32,System.Nullable{System.Char},System.Boolean,Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec)">
            <summary>
            Creates a shingle filter with ad hoc parameter settings.
            </summary>
            <param name="input">stream from which to construct the matrix</param>
            <param name="minimumShingleSize">minimum number of tokens in any shingle.</param>
            <param name="maximumShingleSize">maximum number of tokens in any shingle.</param>
            <param name="spacerCharacter">character to use between texts of the token parts in a shingle. null for none.</param>
            <param name="ignoringSinglePrefixOrSuffixShingle">if true, shingles that only contains permutation of the first of the last column will not be produced as shingles. Useful when adding boundary marker tokens such as '^' and '$'.</param>
            <param name="settingsCodec">codec used to read input token weight and matrix positioning.</param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.Next(Lucene.Net.Analysis.Token)">
            <summary>
            Deprecated: Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer.
            </summary>
            <param name="reusableToken"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.Next">
            <summary>
            Deprecated: Will be removed in Lucene 3.0. This method is final, as it should not be overridden. Delegates to the backwards compatibility layer.
            </summary>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.ProduceNextToken(Lucene.Net.Analysis.Token)">
            <summary>
            This method exists in order to avoid recursive calls to the method
            as the complexity of a fairly small matrix then easily would require
            a gigabyte sized stack per thread.
            </summary>
            <param name="reusableToken"></param>
            <returns>null if exhausted, instance request_next_token if one more call is required for an answer, 
            or instance parameter resuableToken.</returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.NextTokensPermutation">
            <summary>
            Get next permutation of row combinations,
            creates list of all tokens in the row and
            an index from each such token to what row they exist in.
            finally resets the current (next) shingle size and offset. 
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.UpdateToken(Lucene.Net.Analysis.Token,System.Collections.Generic.List{Lucene.Net.Analysis.Token},System.Int32,System.Collections.Generic.List{Lucene.Net.Analyzers.Shingle.Matrix.Row},System.Collections.Generic.List{Lucene.Net.Analysis.Token})">
            <summary>
            Final touch of a shingle token before it is passed on to the consumer from method <see cref="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.Next(Lucene.Net.Analysis.Token)"/>.
            
            Calculates and sets type, flags, position increment, start/end offsets and weight.
            </summary>
            <param name="token">Shingle Token</param>
            <param name="shingle">Tokens used to produce the shingle token.</param>
            <param name="currentPermutationStartOffset">Start offset in parameter currentPermutationTokens</param>
            <param name="currentPermutationRows">index to Matrix.Column.Row from the position of tokens in parameter currentPermutationTokens</param>
            <param name="currentPermuationTokens">tokens of the current permutation of rows in the matrix. </param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.CalculateShingleWeight(Lucene.Net.Analysis.Token,System.Collections.Generic.List{Lucene.Net.Analysis.Token},System.Int32,System.Collections.Generic.List{Lucene.Net.Analyzers.Shingle.Matrix.Row},System.Collections.Generic.List{Lucene.Net.Analysis.Token})">
            <summary>
            Evaluates the new shingle token weight.
            
            for (shingle part token in shingle)
            weight +=  shingle part token weight * (1 / sqrt(all shingle part token weights summed))
            
            This algorithm gives a slightly greater score for longer shingles
            and is rather penalising to great shingle token part weights.
            </summary>
            <param name="shingleToken">token returned to consumer</param>
            <param name="shingle">tokens the tokens used to produce the shingle token.</param>
            <param name="currentPermutationStartOffset">start offset in parameter currentPermutationRows and currentPermutationTokens.</param>
            <param name="currentPermutationRows">an index to what matrix row a token in parameter currentPermutationTokens exist.</param>
            <param name="currentPermuationTokens">all tokens in the current row permutation of the matrix. A sub list (parameter offset, parameter shingle.size) equals parameter shingle.</param>
            <returns>weight to be set for parameter shingleToken </returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.ShingleMatrixFilter.ReadColumn">
            <summary>
            Loads one column from the token stream.
            
            When the last token is read from the token stream it will column.setLast(true);
            </summary>
            <returns>true if it manage to read one more column from the input token stream</returns>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.Codec.OneDimensionalNonWeightedTokenSettingsCodec">
            <summary>
            Using this codec makes a ShingleMatrixFilter act like ShingleFilter.
            It produces the most simple sort of shingles, ignoring token position increments, etc.
            
            It adds each token as a new column.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec">
            <summary>
            Strategy used to code and decode meta data of the tokens from the input stream
            regarding how to position the tokens in the matrix, set and retreive weight, etc.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec.GetTokenPositioner(Lucene.Net.Analysis.Token)">
            <summary>
            Retrieves information on how a Token is to be inserted to a ShingleMatrixFilter.Matrix.
            </summary>
            <param name="token"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec.SetTokenPositioner(Lucene.Net.Analysis.Token,Lucene.Net.Analyzers.Shingle.TokenPositioner)">
            <summary>
            Sets information on how a Token is to be inserted to a ShingleMatrixFilter.Matrix.
            </summary>
            <param name="token"></param>
            <param name="tokenPositioner"></param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec.GetWeight(Lucene.Net.Analysis.Token)">
            <summary>
            Have this method return 1f in order to 'disable' weights.
            </summary>
            <param name="token"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.TokenSettingsCodec.SetWeight(Lucene.Net.Analysis.Token,System.Single)">
            <summary>
            Have this method do nothing in order to 'disable' weights.
            </summary>
            <param name="token"></param>
            <param name="weight"></param>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.Codec.SimpleThreeDimensionalTokenSettingsCodec">
            <summary>
            A full featured codec not to be used for something serious.
            
            It takes complete control of
            payload for weight
            and the bit flags for positioning in the matrix.
            
            Mainly exist for demonstrational purposes.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.SimpleThreeDimensionalTokenSettingsCodec.GetTokenPositioner(Lucene.Net.Analysis.Token)">
            <summary>
            
            </summary>
            <param name="token"></param>
            <returns>the token flags int value as TokenPosition</returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.SimpleThreeDimensionalTokenSettingsCodec.SetTokenPositioner(Lucene.Net.Analysis.Token,Lucene.Net.Analyzers.Shingle.TokenPositioner)">
            <summary>
            Sets the TokenPositioner as token flags int value.
            </summary>
            <param name="token"></param>
            <param name="tokenPositioner"></param>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.SimpleThreeDimensionalTokenSettingsCodec.GetWeight(Lucene.Net.Analysis.Token)">
            <summary>
            Returns a 32 bit float from the payload, or 1f it null.
            </summary>
            <param name="token"></param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analyzers.Shingle.Codec.SimpleThreeDimensionalTokenSettingsCodec.SetWeight(Lucene.Net.Analysis.Token,System.Single)">
            <summary>
            Stores a 32 bit float in the payload, or set it to null if 1f;
            </summary>
            <param name="token"></param>
            <param name="weight"></param>
        </member>
        <member name="T:Lucene.Net.Analyzers.Shingle.Codec.TwoDimensionalNonWeightedSynonymTokenSettingsCodec">
            <summary>
            A codec that creates a two dimensional matrix
            by treating tokens from the input stream with 0 position increment
            as new rows to the current column.
            </summary>
        </member>
        <member name="T:Lucene.Net.Analysis.WordlistLoader">
            <summary>
            Loads a text file and adds every line as an entry to a Hashtable. Every line
            should contain only one word. If the file is not found or on any error, an
            empty table is returned.
            </summary>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordtable(System.String,System.String)">
            <summary>
            Load words table from the file
            </summary>
            <param name="path">Path to the wordlist</param>
            <param name="wordfile">Name of the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordtable(System.String)">
            <summary>
            Load words table from the file
            </summary>
            <param name="wordfile">Complete path to the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordtable(System.IO.FileInfo)">
            <summary>
            Load words table from the file 
            </summary>
            <param name="wordfile">File containing the wordlist</param>
            <returns></returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.GetWordtable(System.IO.TextReader)">
            <summary>
            Reads lines from a Reader and adds every line as an entry to a HashSet (omitting
            leading and trailing whitespace). Every line of the Reader should contain only
            one word. The words need to be in lowercase if you make use of an
            Analyzer which uses LowerCaseFilter (like StandardAnalyzer).
            </summary>
            <param name="reader">Reader containing the wordlist</param>
            <returns>A Hashtable with the reader's words</returns>
        </member>
        <member name="M:Lucene.Net.Analysis.WordlistLoader.MakeWordTable(System.String[],System.Int32)">
            <summary>
            Builds the wordlist table.
            </summary>
            <param name="words">Word that where read</param>
            <param name="length">Amount of words that where read into <tt>words</tt></param>
            <returns></returns>
        </member>
    </members>
</doc>
